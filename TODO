0) work out how to make it testable

1) update/write the docs

3) better connection tracking so we can stop when we're finished
3b) per-request timeouts when server is not responding

4) default check_response_header could do something useful (such as
comparing http status and content-type with the recorded script)

5) There is a limit on the number of timers available
set_max_timers(ct).  

"Sets the maximum number of timers and periodic timers that may be
outstanding at any given time. You only need to call set_max_timers if
you need more than the default number of timers, which on most
platforms is 1000. Call this method before calling EventMachine#run."

From the source:
 /* Allow a user to increase the maximum number of outstanding timers.
  * If this gets "too high" (a metric that is of course platform dependent),
  * bad things will happen like performance problems and possible overuse
  * of memory.
  * The actual timer mechanism is very efficient so it's hard to know what
  * the practical max, but 100,000 shouldn't be too problematical.
  */

We are using C_H (default 2) connections per host per session.
Between requests each connection requires a single timer.  So if we
are hitting a single host our timer use is basically 2x the number of
sessions.  If 1000 is a bottleneck before CPU becomes an issue,
100,000 probably won't be, but we should know how many we're going to
need and advise the user if it needs raising

6) I rather suspect our response parsing is dog-slow, and for load
tests we should replace it with something simpler.  Note that http
headers are all US-ASCII - we don't need to worry about utf-8 or anything

8) Will there ever be a need to add new events on the fly or do we
always know the full set of requests before EM.run is called?  Perhaps
we want to sustain load for ten or twenty minutes to eliminate "ramp
up" effects on a server: do our data structures allow that?

10) socket options - try to get approximately the same TCP behaviour as the 
orginal requests would have had

11) we send an http/1.0 request but handle the response mostly as if
it were 1.1 (chunking excepted) - e.g. we default to persistent
connects.  We should send the same http version that was in the
script, and we should behave accordingly

12) It would be instructve to know whether real browsers always open
two sockets/host or just one - when do they decide the second pipe is
needed?  It's a little bizarre to see the cs being fetched before teh
html tht refers to it.

13) we don't have the standard "block all connections while
downloading a script" behaviour, though maybe that's not a real big
deal as the delays in the original request will simulate it more or
less - until the site gets slow.

18) munge_request should not alter the request in-place because it
will break other users running the same session.  Perhaps instead we
should return a new set of request headers, or something
